{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Data Mining 2016 - Assignment 4: Know your Trade-offs\n",
    "\n",
    "In the last three skills classes we have focussed on understanding the basics of data mining: interpreting your data, creating intuitions, evaluating models, and criticizing the output. This week, you are tasked to an actual data challenge. A very old one.\n",
    "\n",
    "**Note: we will not be present during this practical, the practical rooms are available to you though.** If you have urgent questions regarding this assignment during practical hours, send an email to Chris. \n",
    "\n",
    "## 0.1 - Preparing your Data\n",
    "\n",
    "The file will be available on blackboard, under `mnist.arff`. There is **no** documentation in the `.arff` file, so carefully read the description here or inform yourself a bit further by looking the dataset up on the internet.\n",
    "\n",
    "## 0.2 - Set-up\n",
    "\n",
    "Although not obligatory, or really necessary, having a team might benefit your result. More people means more laptops, means more people to run configurations and trying to improve scores. One of the things you might want to do is making a shared document including a table with ran experiments and their configurations, and what the final score was.\n",
    "\n",
    "## 1 - Getting Started\n",
    "\n",
    "The MNIST dataset consists of pictures of handwritten digits (see below).\n",
    "\n",
    "![img](http://theanets.readthedocs.io/en/latest/_images/mnist-digits-small.png)\n",
    "\n",
    "The feature vectors represent the (grayscale) intensity of every pixel in these 28x28 images (therefore 784 pixels). The class (label) represents the actual number, from 0 to 9. There are 60.000 of these labelled images available, which means it is a very big dataset (105 MB).\n",
    "\n",
    "## 2 - Your Task\n",
    "\n",
    "Your task is to minimize the error of your classifier, so that it would still perform well on new hand-written digits. Note: up until now we have looked at accuracy (correctly classified instances), now we will look at *incorrectly* classified instances (i.e. error). The state-of-the-art performance error is as low as 0.21 percent (that would look like 0.0021 in WEKA). You are not expected to match this anywhere near (as the techniques to achieve this are simply not implemented in WEKA). Use your knowledge of evaluation and parameter tuning you have acquired up until now to build a model you think will perform well.\n",
    "\n",
    "## 3 - Tradeoffs\n",
    "\n",
    "The dataset is very big. Normal machines will take a *lot* of time to get through training and testing of all the instances. To counter this, you can decide to remove part of the dataset. In WEKA this can be done under the `Preprocessing` tab. As follows:\n",
    "\n",
    "- Below the button `Open file...` (below as in its position) there is a `filter` area.\n",
    "- Click `Choose`. Navigate through: `filters -> unsupervised -> instance -> RemovePercentage`.\n",
    "- Click `RemovePercentage` (next to `Choose`) to change the percentage the filter will remove from the data.\n",
    "- Click `Apply`. If successful, the amount of instances should be lower than 60.000.\n",
    "- To regain the full set, simply open it up again.\n",
    "\n",
    "**Important note:** removing data speeds up the classification process; however, it also means you will see less instances. As a result, it will likely hurt the generalization of your classifier. For this assignment, you will have to balance (i.e. trade-off) computation time (mostly your time) and performance.\n",
    "\n",
    "## 4 - Reporting\n",
    "\n",
    "It's good to keep a log with the steps you have taken: the amount of data you have removed, which parameters you tuned to which values, if you used test split or k-fold cross-validation, and how this affected your results. If you feel comfortable with your solution, you can e-mail your set-up to Chris. Please include:\n",
    "\n",
    "- Percentage of data you have removed.\n",
    "- What the evaluation set-up was.\n",
    "- Which classifier you used.\n",
    "- The parameter settings of that classifier that yielded the lowest error.\n",
    "- Your error score.\n",
    "\n",
    "If you worked in a group, include the names of your group members. Next lecture, we will announce the winners.\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
